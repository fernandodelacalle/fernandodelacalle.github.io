<!-- saved from url=(0025)http://fernando.diaz.nyc/ -->
<html itemscope="" itemtype="http://schema.org/Article">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        

        <title>Fernando de la Calle Silos</title>
        <base target="_blank">
        <link rel="stylesheet" href="bare-bones.css">
        <!-- <meta name="description" content="Fernando Diaz conducts research at Spotify. His primary research interest is formal information retrieval models and his research experience includes distributed information retrieval approaches to web search, interaction logging and modeling, interactive and faceted retrieval, mining of temporal patterns from news and query logs, cross-lingual information retrieval, graph-based retrieval methods, and synthesizing information from multiple corpora. ">
        <meta itemprop="name" content="Fernando Diaz">
        <meta itemprop="description" content="Fernando Diaz conducts research at Spotify. His primary research interest is formal information retrieval models and his research experience includes distributed information retrieval approaches to web search, interaction logging and modeling, interactive and faceted retrieval, mining of temporal patterns from news and query logs, cross-lingual information retrieval, graph-based retrieval methods, and synthesizing information from multiple corpora.">
        <meta itemprop="image" content="http://fernando.diaz.nyc/fdiaz.png">
        <meta name="twitter:card" content="summary">
        <meta name="twitter:title" content="Fernando Diaz">
        <meta name="twitter:description" content="Fernando Diaz conducts research at Spotify. His primary research interest is formal information retrieval models and his research experience includes distributed information retrieval approaches to web search, interaction logging and modeling, interactive and faceted retrieval, mining of temporal patterns from news and query logs, cross-lingual information retrieval, graph-based retrieval methods, and synthesizing information from multiple corpora.">
        <meta name="twitter:creator" content="@diazf_acm">
        <meta name="twitter:image:src" content="http://fernando.diaz.nyc/fdiaz.png">
        <meta property="og:title" content="Fernando Diaz">
        <meta property="og:type" content="website">
        <meta property="og:url" content="http://fernando.diaz.nyc/">
        <meta property="og:image" content="http://fernando.diaz.nyc/fdiaz.png">
        <meta property="og:description" content="Fernando Diaz conducts research at Spotify. His primary research interest is formal information retrieval models and his research experience includes distributed information retrieval approaches to web search, interaction logging and modeling, interactive and faceted retrieval, mining of temporal patterns from news and query logs, cross-lingual information retrieval, graph-based retrieval methods, and synthesizing information from multiple corpora."> -->
        <meta name="viewport" content="width=device-width, initial-scale=1">
       
    </head>
    <body>
        <center>
            <table id="mytable">
                <colgroup>
                    <col width="25%">
                    <col width="75%">
                </colgroup>
                <tbody>
                    <tr>
                        <td colspan="2" valign="top">
                            <center>
                                <p class="nameFont"> Fernando de la Calle Silos </p>
                                <img src="fernando.jpg" class="img-circle">
                                <p class="noteFont"> Researcher and Associate Professor <br> Signal Teory and Comunications Department<br>Universidad Carlos III de Madrid</p>
                                <p class="noteFont"> fsilos&nbsp;[at]&nbsp;tsc&nbsp;[dot]&nbsp;uc3m&nbsp;[dot]&nbsp;es </p>


                                <p class="noteFont">
                                    <a href=""><img src="icons/scholar.png" height="16" width="16"></a>
                                    <a href="https://github.com/fernandodelacalle"><img src="icons/GitHub.png" height="16" width="16"></a>
                                    <a href="https://www.linkedin.com/in/fernando-de-la-calle-silos-03399b40"><img src="icons/linkedin.png" height="16" width="16"></a>
                                </p>


                            </center>
                        </td>
                    </tr>
                    <tr>
                        <td valign="top" colspan="2">
                            <center>
                                <p class="hdrFont">Introduction</p>
                            </center>
                        </td>
                    </tr>
                    <tr>
                        <td valign="top" colspan="2">
                            <p align="justify" class="pubFont"> 
                            During my years as a researcher I have developed a deep passion for signal processing and machine learning, focusing on diverse areas such as Speech Recognition and Computer Vision. I am very passionate to be working on these topics as part of my research at University Carlos III of Madrid and Carnegie Mellon University, and would like to keep doing research on related areas.
                            <p align="justify" class="pubFont"> Detailed information can be found on my <a href="cv.pdf">curriculum vitae</a>. </p>
                        </td>
                    </tr>
                    <tr id="pubHeader">
                        <td valign="top" colspan="2">
                            <center>
                                <p class="hdrFont"> Publications </p>
                            </center>
                        </td>
                    </tr>
                    <tr>
                        <td style="vertical-align: top;">
                            <p class="pubFont">Dissertation</p>
                        </td>
                        <td>
                            <p class="pubFont"><a title="Bio-Motivated Features and Deep Learning for Robust Speech Recognition" href="pdfs/phd_Fernando_de_la_Calle.pdf">Bio-Motivated Features and Deep Learning for Robust Speech Recognition</a><br><em>F. de-la-Calle-Silos</em><br>Universidad Carlos III de Madrid, 2017<br></p>
                        </td>
                    </tr>
                    <tr>
                        <td style="vertical-align: top;">
                            <p class="pubFont">Journal</p>
                        </td>
                        <td>
                            <p class="pubFont"><a title="Synchrony-Based Feature Extraction for Robust Automatic Speech Recognition" href="pdfs/2017_08_SPL.pdf">Synchrony-Based Feature Extraction for Robust Automatic Speech Recognition</a><br><em>F. de-la-Calle-Silos and Richard M. Stern</em><br>IEEE Signal Processing Letters, vol. 24, no. 8, pp. 1158, Aug. 2017<br></p>
                        </td>
                    </tr>
                    <tr>
                        <td style="vertical-align: top;"></td>
                        <td>
                            <p class="pubFont"><a title="Morphologically-filtered power-normalized cochleograms as robust, biologically inspired features for ASR" href="pdfs/2015_11_TASP.pdf">Morphologically- filtered power-normalized cochleograms as robust, biologically inspired features for ASR</a><br><em>F. de-la-Calle-Silos, F.J. Valverde-Albacete, A. Gallardo-Antolín, C. Pelaéz-Moreno.</em><br>IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 23, no. 11, pp. 2070-2080, Nov. 2015<br><b>Best indexed 2016 JCR journal publication by the Spanish Thematic Network on Speech Technology (RTTH)</b><br> </p> 
                        </td>
                    </tr>
                    

                    <tr>
                        <td style="vertical-align: top;">
                            <p class="pubFont">International Conferences</p>
                        </td>
                        <td>
                            <p class="pubFont"><a title="Deep Residual Networks with Auditory Inspired Features for Robust Speech Recognition" href="pdfs/2017_restnet.pdf">Deep Residual Networks with Auditory Inspired Features for Robust Speech Recognition</a><br><em>F. de-la-Calle-Silos, A. Gallardo-Antolín, C. Pelaéz-Moreno.</em><br>Intespeech 2017<br></p>
                        </td>
                    </tr>
                    <tr>
                        <td style="vertical-align: top;"></td>
                        <td>
                            <p class="pubFont"><a title="ASR Feature Extraction with Morphologically-Filtered Power-Normalized Cochleograms" href="pdfs/2014_09_INTERSPEECH.pdf">ASR Feature Extraction with Morphologically-Filtered Power-Normalized Cochleograms</a><br><em>F. de-la-Calle-Silos, F.J. Valverde-Albacete, A. Gallardo-Antolín, C. Pelaéz-Moreno.</em><br>International Speech Communication Association (Intespeech), Singapore, September 2014<br></p>
                        </td>
                    </tr>
                    <tr>
                        <td style="vertical-align: top;"></td>
                        <td>
                            <p class="pubFont"><a title="Mid-Level Feature Set for Specific Event and Anomaly Detection in Crowded Scenes." href="pdfs/2013_09_ICIP.pdf">Mid-Level Feature Set for Specific Event and Anomaly Detection in Crowded Scenes.</a><br><em>F. de-la-Calle-Silos, I. González-Díaz, F. Díaz-de-María</em><br>IEEE International Conference of Image Processing (ICIP), Melbourne, Australia. September, 2013. <br> <a href="https://github.com/fernandodelacalle/MI_Feature_Selection_ICIP_2013">Code, </a><a href="">videos</a> and <a href="">poster</a></p>
                        </td>
                    </tr>
                    <tr>
                        <td style="vertical-align: top;">
                            <p class="pubFont">Local Conferences</p>
                        </td>
                        <td>
                            <p class="pubFont"><a title="An Analysis of Deep Neural Networks in Broad Phonetic Classes for Noisy Speech Recognition" href="pdfs/2016_11_IberSpeech.pdf">An Analysis of Deep Neural Networks in Broad Phonetic Classes for Noisy Speech Recognition</a><br><em>F. de-la-Calle-Silos, A. Gallardo-Antolín, C. Pelaéz-Moreno.</em><br>Advances in Speech and Language Technologies for Iberian Languages: Third International Conference, Iberspeech 2016, Lisbon, Portugal, November 23-25, 2016, Proceedings. Lecture Notes in Computer Science<br></p>
                        </td>
                    </tr>
                    <tr>
                        <td style="vertical-align: top;"></td>
                        <td>
                            <p class="pubFont"><a title="Preliminary experiments on the robustness of biologically motivated features for DNN-based ASR" href="pdfs/2015_06_IWOBI.pdf">Preliminary experiments on the robustness of biologically motivated features for DNN-based ASR</a><br><em>F. de-la-Calle-Silos, F.J. Valverde-Albacete, A. Gallardo-Antolín, C. Pelaéz-Moreno.</em><br>4th International Work Conference on Bioinspired Intelligence (IWOBI 15), June 2015<br></p>
                        </td>
                    </tr>
                    <tr>
                        <td style="vertical-align: top;"></td>
                        <td>
                            <p class="pubFont"><a title="Deep Maxout Networks applied to Noise-Robust Speech Recognition" href="pdfs/2014_11_IberSPEECH.pdf">Deep Maxout Networks applied to Noise-Robust Speech Recognition</a><br><em>F. de-la-Calle-Silos, F.J. Valverde-Albacete, A. Gallardo-Antolín, C. Pelaéz-Moreno.</em><br> Advances in Speech and Language Technologies for Iberian Languages. Lecture Notes in Computer Science, Springer 2014.<br></p>
                        </td>
                    </tr>
                    

                    <tr>
                        <td valign="top" colspan="2">
                            <center>
                                <p class="hdrFont">Education</p>
                            </center>
                        </td>
                    </tr>
                    <tr>
                        <td valign="top">
                            <p class="pubFont">Phd</p>
                        </td>
                        <td>
                            <p class="pubFont"><a title="Bio-Motivated Features and Deep Learning for Robust Speech Recognition" href="pdfs/phd_Fernando_de_la_Calle.pdf">Bio-Motivated Features and Deep Learning for Robust Speech Recognition</a><br>PhD in Multimedia and Communications<br>University Carlos III de Madrid<br>Jun 2013 - Sep 2017<br>Cum laude distinction and Ph.D. Outstanding Thesis Award.</p>
                        </td>
                    </tr>
                    <tr>
                        <td valign="top">
                            <p class="pubFont">MSc</p>
                        </td>
                        <td>
                            <p class="pubFont">Master in Multimedia and Communications.<br>University Carlos III de Madrid<br>Sep 2012 - Jun 2013</p>
                        </td>
                    </tr>
                    <tr>
                        <td valign="top">
                            <p class="pubFont">BSc</p>
                        </td>
                        <td>
                            <p class="pubFont">Bachelor in Telecommunication Technology Engineering<br>University Carlos III de Madrid<br>Sep 2008 - Jun 2012<br>Dissertation: <a href="pdfs/tfg/TFG.pdf">Event Recognition in Crowded Scenes</a><br>Best Academic Record Graduation Award</p>


                        </td>
                    </tr>

                   


                    <tr>
                        <td valign="top" colspan="2">
                            <center>
                                <p class="hdrFont"> Teaching </p>
                            </center>
                        </td>
                    </tr>
                    <tr>
                        <td valign="top">
                            <p class="pubFont"></p>
                        </td>
                        <td>
                            <p class="pubFont"><a href="https://aplicaciones.uc3m.es/cpa/generaFicha?est=227&asig=15936&idioma=2">Speech, Audio, Image, and Video Processing Applications</a><br>Master in Telecommunications Engineering<br>University Carlos III de Madrid<br>Fall 2017</p>
                        </td>
                    </tr>
                   
                    <tr>
                        <td valign="top">
                            <p class="pubFont"></p>
                        </td>
                        <td>
                            <p class="pubFont"><a href="https://aplicaciones.uc3m.es/cpa/generaFicha?est=252&asig=15402&idioma=2">Algorithms for Multimedia Information Management </a><br>Bachelor in Telecommunication Technology Engineering<br>University Carlos III de Madrid<br>Fall 2016, Fall 2017</p>
                        </td>
                    </tr>

                    <tr>
                        <td valign="top">
                            <p class="pubFont"></p>
                        </td>
                        <td>
                            <p class="pubFont"><a href="https://aplicaciones.uc3m.es/cpa/generaFicha?est=217&asig=13850&idioma=2">Multimedia Information Coding in Communications</a><br>Bachelor in Communication System Engineering<br>University Carlos III de Madrid<br>Spring 2018</p>
                        </td>
                    </tr>


                    <tr>
                        <td valign="top">
                            <p class="pubFont"></p>
                        </td>
                        <td>
                            <p class="pubFont"><a href="https://aplicaciones.uc3m.es/cpa/generaFicha?est=214&asig=13356&idioma=2">Acoustical Instrumentation and Noise Control</a><br>Bachelor in Audiovisual System Engineering<br>University Carlos III de Madrid<br>Fall 2016, Fall 2017</p>
                        </td>
                    </tr>

                    <tr>
                        <td valign="top">
                            <p class="pubFont"></p>
                        </td>
                        <td>
                            <p class="pubFont"><a href="https://aplicaciones.uc3m.es/cpa/generaFicha?est=214&asig=14822&idioma=2">Digital Audio Processing</a><br>Bachelor in Audiovisual System Engineering<br>University Carlos III de Madrid<br>Fall 2017</p>
                        </td>
                    </tr>






                    <tr>
                        <td valign="top" colspan="2">
                            <center>
                                <p class="hdrFont"> Code </p>
                            </center>
                        </td>
                    </tr>
                    <tr>
                        <td valign="top">
                            <p class="pubFont"></p>
                        </td>
                        <td>
                            <p class="pubFont"><b><a href="https://github.com/fernandodelacalle/fsilosSpeechToolbox">fsilosSpeechToolbox</a></b>:
                            Implementation of all the feature extraction methods presented in my PhD thesis.</p>
                            <p class="pubFont"><b><a href="https://github.com/fernandodelacalle/ResNet-Kaldi-Tensorflow-ASR">ResNet-Kaldi-Tensorflow-ASR</a></b>:
                            ResNet and other CNN implementations in Tensorflow presented in the paper: Deep Residual Networks with Auditory Inspired Features for Robust Speech Recognition.</p>
                            <p class="pubFont"><b><a href="https://github.com/fernandodelacalle/MI_Feature_Selection_ICIP_2013">MI_Feature_Selection</a></b>: Matlab code that implements the feature selection algorithm using mutual information described in the ICIP 2013 paper</p>
                        </td>
                    </tr>
                </tbody>
            </table>
        </center>
    </body>
</html>